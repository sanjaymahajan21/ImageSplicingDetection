{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyORDCETuoZot1DH6m9a/KfD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjaymahajan21/ImageSplicingDetection/blob/main/MTech_Final_Project_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEtksnhF423K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b0b49f-27e0-4af2-c223-750b2ff50898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using pretrained network\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import json\n",
        "\n",
        "\n",
        "#prepare dataset-1 \"Real and Fake Face Detection\" \"https://www.kaggle.com/datasets/ciplab/real-and-fake-face-detection?resource=download\"\n",
        "train_path = '/content/drive/MyDrive/KaggleRealandFakeFaceDetection/train'\n",
        "valid_path = '/content/drive/MyDrive/KaggleRealandFakeFaceDetection/valid'\n",
        "test_path = '/content/drive/MyDrive/KaggleRealandFakeFaceDetection/test'\n",
        "\n",
        "\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(train_path, target_size=(224,224), batch_size=10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(valid_path, target_size=(224,224), batch_size=10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10)\n"
      ],
      "metadata": {
        "id": "NtCtL5pw48WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f7c243-b98c-4d92-9461-de01afa24c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1633 images belonging to 2 classes.\n",
            "Found 306 images belonging to 2 classes.\n",
            "Found 102 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Module using VGG16 pretrained architecture\n",
        "\n",
        "\n",
        "input_tensor = tf.keras.layers.Input(shape=(224,224,3))\n",
        "\n",
        "base_model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model1 = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "#opt: This is a variable name representing the optimizer object.\n",
        "#SGD: It stands for Stochastic Gradient Descent, which is the optimization algorithm being used.\n",
        "#lr=1e-4: It specifies the learning rate for the optimizer. The learning rate determines the step size at which the optimizer adjusts the model's parameters during training. In this case, the learning rate is set to 10^(-4), which is a small value indicating cautious and slower updates.\n",
        "#momentum=0.9: Momentum is a hyperparameter that affects the convergence speed and behavior of the optimizer. It helps accelerate gradient descent in the relevant direction and dampens oscillations. A momentum value of 0.9 means that the optimizer takes into account 90% of the previously accumulated gradients to influence the current update.\n",
        "\n",
        "\n",
        "callback_list=[EarlyStopping(monitor=\"val_loss\",patience=100),ModelCheckpoint(filepath=\"/content/drive/MyDrive/VGG16TEST-OUTPUT.h5\",monitor=\"val_loss\",save_best_only=True,verbose=1)]\n",
        "\n",
        "\n",
        "model1.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "history = model1.fit_generator(train_batches,validation_data=valid_batches,epochs=5,verbose=1,callbacks=callback_list)\n",
        "print(\"Number of CNN layers:\", len(base_model.layers))\n",
        "#STORING HISTORY OF TRAINING FOR LATER USE\n",
        "with open(\"history.json\", \"w\") as f:\n",
        "    json.dump(history.history, f)"
      ],
      "metadata": {
        "id": "ynRykU-r4-cM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed5f2a7-dc5f-43b3-e4f4-f0bbac746ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,980,737\n",
            "Trainable params: 27,266,049\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-709d399f9871>:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model1.fit_generator(train_batches,validation_data=valid_batches,epochs=5,verbose=1,callbacks=callback_list)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "164/164 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5000\n",
            "Epoch 1: val_loss did not improve from inf\n",
            "164/164 [==============================] - 829s 5s/step - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "164/164 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5000\n",
            "Epoch 2: val_loss did not improve from inf\n",
            "164/164 [==============================] - 31s 190ms/step - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "164/164 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5000\n",
            "Epoch 3: val_loss did not improve from inf\n",
            "164/164 [==============================] - 31s 190ms/step - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "164/164 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5000\n",
            "Epoch 4: val_loss did not improve from inf\n",
            "164/164 [==============================] - 31s 190ms/step - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "164/164 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5000\n",
            "Epoch 5: val_loss did not improve from inf\n",
            "164/164 [==============================] - 31s 190ms/step - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Number of CNN layers: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def load_model_evaluate(model_path, test_data_generator):\n",
        "    # Load the model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Generate predictions\n",
        "    test_data = test_data_generator\n",
        "    y_true = test_data.classes\n",
        "    y_pred_prob = model.predict(test_data)\n",
        "    y_pred = np.round(y_pred_prob).flatten()\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(\"accuracy : \",accuracy)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"confusion matrix : \", cm)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    print(\"precision : \",precision)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    print(\"recall : \",recall)\n",
        "\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(\"f1 score : \",f1)\n",
        "\n",
        "    return accuracy, cm, precision, recall, f1\n",
        "\n",
        "\n",
        "\n",
        "load_model_evaluate(\"/content/drive/MyDrive/VGG16TEST-OUTPUT.h5\",test_batches)"
      ],
      "metadata": {
        "id": "y75qYRS25RNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f062c882-4608-49ee-c532-79e3721b4d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 66s 7s/step\n",
            "accuracy :  0.5294117647058824\n",
            "confusion matrix :  [[ 0 48]\n",
            " [ 0 54]]\n",
            "precision :  0.5294117647058824\n",
            "recall :  1.0\n",
            "f1 score :  0.6923076923076924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5294117647058824,\n",
              " array([[ 0, 48],\n",
              "        [ 0, 54]]),\n",
              " 0.5294117647058824,\n",
              " 1.0,\n",
              " 0.6923076923076924)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import json\n",
        "\n",
        "\n",
        "#prepare dataset-2 \"COVID-19 Digital X-rays Forgery Dataset\" \"https://www.kaggle.com/datasets/nourmahmoud/covid19-digital-xrays-forgery-dataset?resource=download\"\n",
        "train_path ='/content/drive/MyDrive/KaggleRealandFakeCovid19XRAYDetection/train'\n",
        "valid_path ='/content/drive/MyDrive/KaggleRealandFakeCovid19XRAYDetection/valid'\n",
        "test_path ='/content/drive/MyDrive/KaggleRealandFakeCovid19XRAYDetection/test'\n",
        "\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(train_path, target_size=(224,224), batch_size=10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(valid_path, target_size=(224,224), batch_size=10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO2ByNNbucKT",
        "outputId": "8062c990-d9d9-47b3-fc83-7f72c2f7754b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3200 images belonging to 2 classes.\n",
            "Found 600 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Module using VGG16 pretrained architecture\n",
        "\n",
        "\n",
        "input_tensor = tf.keras.layers.Input(shape=(224,224,3))\n",
        "\n",
        "base_model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model1 = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "#opt: This is a variable name representing the optimizer object.\n",
        "#SGD: It stands for Stochastic Gradient Descent, which is the optimization algorithm being used.\n",
        "#lr=1e-4: It specifies the learning rate for the optimizer. The learning rate determines the step size at which the optimizer adjusts the model's parameters during training. In this case, the learning rate is set to 10^(-4), which is a small value indicating cautious and slower updates.\n",
        "#momentum=0.9: Momentum is a hyperparameter that affects the convergence speed and behavior of the optimizer. It helps accelerate gradient descent in the relevant direction and dampens oscillations. A momentum value of 0.9 means that the optimizer takes into account 90% of the previously accumulated gradients to influence the current update.\n",
        "\n",
        "\n",
        "callback_list=[EarlyStopping(monitor=\"val_loss\",patience=100),ModelCheckpoint(filepath=\"/content/drive/MyDrive/VGG16TEST-OUTPUT.h5\",monitor=\"val_loss\",save_best_only=True,verbose=1)]\n",
        "\n",
        "\n",
        "model1.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "history = model1.fit_generator(train_batches,validation_data=valid_batches,epochs=5,verbose=1,callbacks=callback_list)\n",
        "print(\"Number of CNN layers:\", len(base_model.layers))\n",
        "#STORING HISTORY OF TRAINING FOR LATER USE\n",
        "with open(\"history.json\", \"w\") as f:\n",
        "    json.dump(history.history, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoXu_t3_up_v",
        "outputId": "0d487fd3-63c2-44b0-c000-5165dd43fe54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,980,737\n",
            "Trainable params: 27,266,049\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-709d399f9871>:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model1.fit_generator(train_batches,validation_data=valid_batches,epochs=5,verbose=1,callbacks=callback_list)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "320/320 [==============================] - ETA: 0s - loss: 1.4848 - accuracy: 0.5000\n",
            "Epoch 1: val_loss improved from inf to 0.69315, saving model to /content/drive/MyDrive/VGG16TEST-OUTPUT.h5\n",
            "320/320 [==============================] - 1507s 5s/step - loss: 1.4848 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "320/320 [==============================] - ETA: 0s - loss: 0.7002 - accuracy: 0.5000\n",
            "Epoch 2: val_loss did not improve from 0.69315\n",
            "320/320 [==============================] - 24s 76ms/step - loss: 0.7002 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "320/320 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 3: val_loss improved from 0.69315 to 0.69315, saving model to /content/drive/MyDrive/VGG16TEST-OUTPUT.h5\n",
            "320/320 [==============================] - 29s 92ms/step - loss: 0.6957 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "320/320 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 4: val_loss improved from 0.69315 to 0.69315, saving model to /content/drive/MyDrive/VGG16TEST-OUTPUT.h5\n",
            "320/320 [==============================] - 29s 90ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "320/320 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 5: val_loss did not improve from 0.69315\n",
            "320/320 [==============================] - 25s 77ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Number of CNN layers: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def load_model_evaluate(model_path, test_data_generator):\n",
        "    # Load the model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Generate predictions\n",
        "    test_data = test_data_generator\n",
        "    y_true = test_data.classes\n",
        "    y_pred_prob = model.predict(test_data)\n",
        "    y_pred = np.round(y_pred_prob).flatten()\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(\"accuracy : \",accuracy)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"confusion matrix : \", cm)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    print(\"precision : \",precision)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    print(\"recall : \",recall)\n",
        "\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(\"f1 score : \",f1)\n",
        "\n",
        "    return accuracy, cm, precision, recall, f1\n",
        "\n",
        "\n",
        "\n",
        "load_model_evaluate(\"/content/drive/MyDrive/VGG16TEST-OUTPUT.h5\",test_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QQFR-imuwd7",
        "outputId": "626365a2-987b-4e4b-f8d8-9548cba93c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 129s 7s/step\n",
            "accuracy :  0.505\n",
            "confusion matrix :  [[  1  99]\n",
            " [  0 100]]\n",
            "precision :  0.5025125628140703\n",
            "recall :  1.0\n",
            "f1 score :  0.6688963210702341\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.505,\n",
              " array([[  1,  99],\n",
              "        [  0, 100]]),\n",
              " 0.5025125628140703,\n",
              " 1.0,\n",
              " 0.6688963210702341)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}